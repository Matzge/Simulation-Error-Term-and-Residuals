{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of disturbance term and residuals.....\n",
    "\n",
    "I want to show the difference between the residuals and the disturbance term.\n",
    "Moreover, I show some properties.\n",
    "\n",
    "## I assume i know the true model:\n",
    "\n",
    "$ Y =\\beta_1 + \\beta_2*X +u$ <br>\n",
    "**Coefficents of the true Model: <br>\n",
    "$\\beta_1 = 0$** <br>\n",
    "$\\beta_2 = 1$ <br>\n",
    "\n",
    "I calculate some Values for the true population regression model.\n",
    "I use the constructed Values to calculate an estimated model and \n",
    "show that it is not necesserily equal to the true model.I sum all \n",
    "residuals and all errors to show that the sum of errors is none zero \n",
    "and the sum of residuals is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.243\n",
      "Model:                            OLS   Adj. R-squared:                  0.168\n",
      "Method:                 Least Squares   F-statistic:                     3.215\n",
      "Date:                Mon, 08 Jul 2019   Prob (F-statistic):              0.103\n",
      "Time:                        18:32:06   Log-Likelihood:                -42.518\n",
      "No. Observations:                  11   AIC:                             87.04\n",
      "Df Residuals:                      10   BIC:                             87.43\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.1065      0.617      1.793      0.103      -0.269       2.482\n",
      "==============================================================================\n",
      "Omnibus:                        3.112   Durbin-Watson:                   1.837\n",
      "Prob(Omnibus):                  0.211   Jarque-Bera (JB):                1.727\n",
      "Skew:                           0.960   Prob(JB):                        0.422\n",
      "Kurtosis:                       2.708   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[-0.22083859512035706, -8.464835276031259, -12.093582322110795, -8.891981925537532, 25.845768441764054, 7.554271863593817, 0.19747570702984873, -4.8909434610632445, 2.8882321039002345, 27.86893710590838, 10.330842647654883]\n",
      "Sum of errors:  -14.876653710011972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/stats/stats.py:1416: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=11\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "list_y = [] \n",
    "list_x = []\n",
    "list_error = []\n",
    "list_residuals = []\n",
    "\n",
    "for i in range(0, 11):\n",
    "    list_x.append(i)\n",
    "    y = i + np.random.normal(0, 10)\n",
    "    list_y.append(y)\n",
    "\n",
    "\n",
    "model = sm.OLS(list_y,list_x).fit()\n",
    "predictions = model.predict(list_x)\n",
    "print(model.summary())\n",
    "\n",
    "print(list_y)\n",
    "#print(list_x)\n",
    "\n",
    "for k in range(len(list_y)):                 # I calculate the errors as the difference between my actual values \n",
    "    error = list_y[k] - list_x[k]            # from the values i got of by the model....\n",
    "    list_error.append(error)\n",
    "    \n",
    "#print(list_error)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Sum of errors: \", sum(list_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clearly the sum of Errors is always unequal to zero, whereas the sum of residuals of the model\n",
    "have to be zero by definioton of the model** <br>\n",
    "<br>\n",
    "I take the coefficent of the former observation to generate the residuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22083859512035706, -8.464835276031259, -12.093582322110795, -8.891981925537532, 25.845768441764054, 7.554271863593817, 0.19747570702984873, -4.8909434610632445, 2.8882321039002345, 27.86893710590838, 10.330842647654883]\n",
      "[0.0, 1.1065, 2.213, 3.3195, 4.426, 5.532500000000001, 6.639, 7.7455, 8.852, 9.9585, 11.065000000000001]\n",
      "[-0.22083859512035706, -9.57133527603126, -14.306582322110796, -12.211481925537532, 21.419768441764056, 2.021771863593816, -6.4415242929701515, -12.636443461063244, -5.963767896099766, 17.91043710590838, -0.7341573523451181]\n",
      "Sum of the residuals -0.7341573523451181\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "list_y = [-0.22083859512035706, -8.464835276031259, -12.093582322110795, -8.891981925537532, 25.845768441764054, 7.554271863593817, 0.19747570702984873, -4.8909434610632445, 2.8882321039002345, 27.86893710590838, 10.330842647654883]\n",
    "list_residuals = []\n",
    "list_predicted_y = []\n",
    "    \n",
    "for t in range(len(list_y)):\n",
    "    predicted_y = 1.1065*t\n",
    "    list_predicted_y.append(predicted_y)\n",
    "    \n",
    "\n",
    "for k in range(len(list_y)):\n",
    "    sum_residuals = 0;\n",
    "    residual = list_y[k] - list_predicted_y[k]\n",
    "    list_residuals.append(residual)\n",
    "    sum_residuals += residual\n",
    "    #print(residual)\n",
    "    \n",
    "\n",
    "print(list_y)\n",
    "print(list_predicted_y)\n",
    "print(list_residuals)\n",
    "\n",
    "print(\"Sum of the residuals\", sum_residuals)\n",
    "print(list_predicted_y[5] + list_residuals[5] - list_y[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the sum of residuals is smaller than the sum of disturbances. The only reason it is not zero is that\n",
    "i had to take a coefficient from the regression which is a rounded value....."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
